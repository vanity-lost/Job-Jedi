{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.document_loaders import Docx2txtLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import Docx2txtLoader\n",
    "from langchain.agents import initialize_agent, AgentType, Tool\n",
    "\n",
    "from backend import config\n",
    "from backend.feedback import FeedbackBot\n",
    "from backend.resume_generation import ResumeGenerator\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = config.OPENAI_API_KEY"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. QAchain input_document?\n",
    "2. Agent\n",
    "3. Job Description Length\n",
    "4. Summary Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_bot = FeedbackBot()\n",
    "resume_generator = ResumeGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Update Prompts\",\n",
    "        func=feedback_bot.run,\n",
    "        description=\"useful for when you need to re-generate the resume based on user request. Users may have special requirements and preferences and you will need to use this function to update the resume. For example, `more project experience` will be the input if you want to have more project experiences.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name = \"Generate Resume\",\n",
    "        func=resume_generator.run,\n",
    "        description=\"useful for when you need to generate resume and the user does not have specific requirements. If the user have no new instructions, you will need to use this function to generate a new resume. For example, `` be will the input if you want to generate a resume.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION, verbose=True, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description = \"\"\"\n",
    "About the job\n",
    "Organization: Accenture Federal Services\n",
    "\n",
    "Locations: Washington, DC\n",
    "\n",
    "We are:  \n",
    "\n",
    "Accenture Federal Services, helping our federal clients tackle their toughest challenges while unleashing their fullest potential…and then some. What makes our approach so unique? Operating from the nation’s capital, we bring together commercial innovation and leading-edge technologies to deliver an integrated and interactive experience that far exceeds expectations. How? Our passion meets purpose! Through our diverse culture and inclusive thinking, we embrace our employees' ideas taking them from concept to practical solutions. Not to mention, we sleep well at night knowing our work directly impacts and improves the way the world works. We keep our tech smarts sharp by providing abundant training and certification opportunities. Are you ready to learn and grow in a career, while making a difference? You are:  A lover of patterns. Perhaps you grew up putting together 1,000-piece puzzles, finding that tiny detail that gave away the perfect placement. You're on your A-game with the latest tools and methods, from statistics to machine learning. While others were struggling through stats, you were living your best life. You lead the charge to work with business stakeholders to understand their goals and determine how data can be used. What sets you apart? Unlike the rest, you see and apply your work through a human lens. You live to take any data mess from drab to fab and transform it into a story that the average Joe and Jane can understand.  The work:\n",
    "\n",
    "Work with clients to create questions and define technology opportunities\n",
    "\n",
    "Drive the exploration of data sources and analytic techniques to create new modeling approaches\n",
    "\n",
    "Work with large data sets to solve complex problems\n",
    "\n",
    "Apply statistical methods to develop analytic models\n",
    "\n",
    "Potentially manage a technical team to solve clients’ solutions and expectations\n",
    "\n",
    "Here's what experience you need:\n",
    "\n",
    "Data programing languages to script, and analyze data using Python and/or R\n",
    "\n",
    "Conducting complex queries in SQL or similar database language\n",
    "\n",
    "Analytics and statistical modeling to collect, analyze and interpret data sets\n",
    "\n",
    "Consulting or similar field requiring client collaboration, presentation, and delivery \n",
    "\n",
    "Extracting data, aggregating, and structuring data along different dimensions\n",
    "\n",
    "Bachelor's degree\n",
    "\n",
    "US Citizenship required; dual citizens not eligible\n",
    "\n",
    "Compensation for roles at Accenture Federal Services varies depending on a wide array of factors including but not limited to the specific office location, role, skill set and level of experience. As required by local law, Accenture Federal Services provides a reasonable range of compensation for roles that may be hired in California, Colorado, New York City or Washington as set forth below and information on benefits offered is here.   \n",
    "\n",
    "Role Location: Range of Starting Pay for role \n",
    "\n",
    "California: $90,700 - $198,800\n",
    "\n",
    "Colorado: $90,700 - $171,700\n",
    "\n",
    "New York City: $105,000 - $198,800\n",
    "\n",
    "Washington: $96,600 - $182,800\n",
    "\n",
    "Important information\n",
    "\n",
    "An active security clearance or the ability to obtain one may be required for this role.\n",
    "\n",
    "What We Believe\n",
    "\n",
    "We have an unwavering commitment to diversity with the aim that every one of our people has a full sense of belonging within our organization. As a business imperative, every person at Accenture has the responsibility to create and sustain an inclusive environment.\n",
    "\n",
    "Inclusion and diversity are fundamental to our culture and core values. Our rich diversity makes us more innovative and more creative, which helps us better serve our clients and our communities. Read more here\n",
    "\n",
    "Equal Employment Opportunity Statement\n",
    "\n",
    "Accenture is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion or sexual orientation.\n",
    "\n",
    "All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.\n",
    "\n",
    "Accenture is committed to providing veteran employment opportunities to our service men and women.\n",
    "\n",
    "For details, view a copy of the Accenture Equal Opportunity and Affirmative Action Policy Statement.\n",
    "\n",
    "Requesting An Accommodation\n",
    "\n",
    "Accenture is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired.\n",
    "\n",
    "If you would like to be considered for employment opportunities with Accenture and have accommodation needs for a disability or religious observance, please call us toll free at 1 (877) 889-9009, send us an email or speak with your recruiter.\n",
    "\n",
    "Other Employment Statements\n",
    "\n",
    "Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States.\n",
    "\n",
    "Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.\n",
    "\n",
    "Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.\n",
    "\n",
    "The Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Additionally, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company's legal duty to furnish information.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are given the detailed job description \\n {job} \\n.\n",
    "Based on the job description, extract the required information, generate a concise summary.\n",
    "Using the job description, extract the job/position title, company name, company position, specific teams/departments, any requirements (including the basic and preferred requirements), the description of expected responsibilities and expected personalities. \n",
    "IMPORTANT: You need to keep your words concise and not miss any important information. \n",
    "\n",
    "Past user requests:\n",
    "None\n",
    "\n",
    "generated resume:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 1549\n",
      "\tPrompt Tokens: 1409\n",
      "\tCompletion Tokens: 140\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.03098\n"
     ]
    }
   ],
   "source": [
    "rephrase_template = PromptTemplate(\n",
    "    input_variables=[\n",
    "        \"job\",\n",
    "    ],\n",
    "    template=template,\n",
    ")\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "rephrase_chain = LLMChain(llm=llm,\n",
    "                          prompt=rephrase_template,\n",
    "                          verbose=False)\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    res = rephrase_chain.run(job=job_description)\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False\n",
    "background_path = './Samplebackground.docx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config.REPHRASE_PROMPT_TEMPLATE_PATH) as f:\n",
    "    REPHRASE_PROMPT_TEMPLATE = f.read()\n",
    "with open(config.JOB_SUMMARY_PROMPT_PATH) as f:\n",
    "    JOB_SUMMARY_PROMPT = f.read()\n",
    "\n",
    "with open(config.LATEX_PROMPT_TEMPLATE_1_PATH) as f:\n",
    "    LATEX_PROMPT_TEMPLAT_1 = f.read()\n",
    "with open(config.LATEX_PROMPT_TEMPLATE_2_PATH) as f:\n",
    "    LATEX_PROMPT_TEMPLAT_2 = f.read()\n",
    "\n",
    "with open(config.LATEX_HEADER_PATH) as f:\n",
    "    latex_header = f.read()\n",
    "\n",
    "with open(config.LATEX_PART1_PATH) as f:\n",
    "    part1 = f.read()\n",
    "\n",
    "with open(config.LATEX_PART2_PATH) as f:\n",
    "    part2 = f.read()\n",
    "\n",
    "llm = OpenAI(max_tokens=1200)\n",
    "\n",
    "job_template = PromptTemplate(\n",
    "    input_variables=[\n",
    "        \"job\",\n",
    "    ],\n",
    "    template=JOB_SUMMARY_PROMPT,\n",
    ")\n",
    "job_summary_chain = LLMChain(llm=llm,\n",
    "                                prompt=job_template,\n",
    "                                verbose=verbose)\n",
    "job_summary = job_summary_chain.run(job=job_description)\n",
    "logging.info('The job summary is generated.')\n",
    "\n",
    "loader = Docx2txtLoader(background_path)\n",
    "background_info = loader.load()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=2000, chunk_overlap=0)\n",
    "background_info_doc = text_splitter.split_documents(background_info)\n",
    "\n",
    "rephrase_template = PromptTemplate(\n",
    "    input_variables=[\n",
    "        \"background\",\n",
    "        \"job\",\n",
    "    ],\n",
    "    template=REPHRASE_PROMPT_TEMPLATE,\n",
    ")\n",
    "rephrase_chain = LLMChain(llm=llm,\n",
    "                            prompt=rephrase_template,\n",
    "                            verbose=verbose)\n",
    "\n",
    "results = []\n",
    "for part in background_info_doc:\n",
    "    res = rephrase_chain.run(background=part, job=job_summary)\n",
    "    results.append(res)\n",
    "\n",
    "background_info_generated = '\\n\\n'.join(results)\n",
    "logging.info('The background summary is generated.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nName: Zara Patel \\nAge: 27 \\nEmail: zara.patel23@gmail.com \\nPhone Number: +1 (555) 555-1212 \\n\\nBackground Summary:\\nZara Patel is a highly motivated and experienced data scientist with a passion for problem-solving and personal growth. She earned a degree in Computer Science from UC Berkeley and has since worked in roles such as CTO and project manager in Silicon Valley. In her free time, she enjoys traveling, cooking, hiking, and playing the guitar, and also volunteers at a local animal shelter. \\n\\nWorking Experience:\\nBanana Ink, Silicon Valley \\nCTO, 2015-Current \\n• Developed predictive maintenance model for industrial equipment, using Python and scikit-learn\\n• Created a web application for technicians to view model predictions and schedule maintenance\\n• Integrated model into industrial engineering team’s equipment maintenance process\\n\\nCustomer Segmentation for Retail Company, R \\n• Leveraged SQL and other database languages to conduct complex queries \\n• Applied analytics and statistical modeling to collect, analyze, and interpret data sets \\n• Developed new modeling approaches to explore data sources and technology opportunities\\n• Managed a technical team to solve clients’ solutions and expectations\\n\\nSkills: Python, scikit-learn, web development, data visualization, machine learning, statistics, SQL, database languages\\n\\n\\n\\nData Scientist with 8+ years of experience in applying data science approaches to solve complex problems in a wide variety of industries. Experienced in data programming languages, such as Python and R, to script and analyze data. Possess expertise in conducting complex queries in SQL and other database languages, and in using analytics and statistical modeling to collect, analyze, and interpret data sets.\\n\\nHighlights of Experience:\\n\\n• Conducted exploratory data analysis on customer purchasing patterns using R, resulting in improved customer segmentation. Applied unsupervised learning techniques such as k-means clustering and hierarchical clustering to segment customers based on their behavior. Developed a dashboard using Shiny to visualize the segments and provide insights to the business team.\\n\\n• Built a convolutional neural network to identify objects in images captured by a camera on an autonomous vehicle. Optimized the model using techniques such as data augmentation and transfer learning. Integrated the model into the vehicle's software system to enable real-time object recognition and decision-making.\\n\\n• Developed a machine learning model to identify fraudulent transactions in real time. Incorporated data from multiple sources, including transaction logs, customer behavior patterns, and external databases. Built an API to allow the model to be easily integrated into the company's existing transaction processing system.\\n\\nSkills:\\n\\nR, Python, SQL, data analysis, unsupervised learning, data visualization, deep learning, computer vision, data preprocessing, software integration, communication, machine learning, API development, financial services.\\n\\n\\n\\nData Scientist with 7+ years of experience in data programming, analytics, and statistical modeling. Proven track record of developing complex queries in SQL, developing recommendation systems using collaborative and content-based filtering techniques, and building dashboards to visualize data. Adept at applying machine learning, natural language processing, and time series analysis to improve data quality and patient outcomes.\\n\\nEXPERIENCE\\n\\nTrained a Named Entity Recognition Model | Accenture Federal Services | Washington, DC\\nUtilized a combination of rule-based and machine learning approaches to create a Named Entity Recognition Model. Integrated the model into the company's electronic health record system to improve data quality and patient outcomes. Collaborated with medical professionals to refine the system's accuracy and performance.\\n\\nTime Series Forecasting Model for Energy Company | Accenture Federal Services | Washington, DC\\nBuilt a forecasting model to predict energy demand using historical time series data. Applied seasonal decomposition, autocorrelation analysis, and ARIMA modeling to identify patterns in the data. Developed a dashboard using Shiny to visualize the forecasts and insights for the energy trading team. Collaborated with the engineering team to ensure scalability of the model.\\n\\nRecommendation System for E-commerce Company | Accenture Federal Services | Washington, DC\\nDeveloped a recommendation system to suggest products to customers based on their browsing and purchasing history. Used collaborative filtering and content-based filtering techniques to generate personalized recommendations. Built a web application to display the recommendations and allow customers to provide feedback on their preferences.\\n\\nSKILLS\\n\\nPython, Natural Language Processing, Machine Learning, Healthcare, Software Integration, R, Time Series Analysis, Forecasting, Data Visualization, Software Engineering\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background_info_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open( './backend/prompts/modified/background_section_1.txt') as f:\n",
    "    BACKGROUND_SECTION_TEMPLATE_1 = f.read()\n",
    "with open( './backend/prompts/modified/background_section_2.txt') as f:\n",
    "    BACKGROUND_SECTION_TEMPLATE_2 = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "background_template = PromptTemplate(\n",
    "    input_variables=[\n",
    "        \"background\",\n",
    "    ],\n",
    "    template=BACKGROUND_SECTION_TEMPLATE_1,\n",
    ")\n",
    "\n",
    "llm = OpenAI(max_tokens=1200, temperature=0.9)\n",
    "\n",
    "background_section_chain = LLMChain(llm=llm,\n",
    "                                prompt=background_template,\n",
    "                                verbose=verbose)\n",
    "background_section = background_section_chain.run(background=background_info_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nName: Zara Patel \\nAge: 27 \\nEmail: zara.patel23@gmail.com \\nPhone Number: +1 (555) 555-1212 \\n\\nEducation: \\nComputer Science degree from UC Berkeley \\n\\nWorking Experience: \\nBanana Ink, Silicon Valley \\nCTO, 2015-Current \\n• Developed predictive maintenance model for industrial equipment, using Python and scikit-learn \\n• Created a web application for technicians to view model predictions and schedule maintenance \\n• Integrated model into industrial engineering team’s equipment maintenance process \\n\\nCustomer Segmentation for Retail Company, R \\n• Leveraged SQL and other database languages to conduct complex queries \\n• Applied analytics and statistical modeling to collect, analyze, and interpret data sets \\n• Developed new modeling approaches to explore data sources and technology opportunities \\n• Managed a technical team to solve clients’ solutions and expectations \\n\\nSkills:\\nPython, scikit-learn, web development, data visualization, machine learning, statistics, SQL, database languages, R, Natural Language Processing, Forecasting, Data Visualization, Software Engineering.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background_section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "background_template = PromptTemplate(\n",
    "    input_variables=[\n",
    "        \"background\",\n",
    "    ],\n",
    "    template=BACKGROUND_SECTION_TEMPLATE_2,\n",
    ")\n",
    "\n",
    "background_section_chain = LLMChain(llm=llm,\n",
    "                                prompt=background_template,\n",
    "                                verbose=verbose)\n",
    "background_section = background_section_chain.run(background=background_info_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nProject Experience:\\n• Developed predictive maintenance model for industrial equipment, using Python and scikit-learn\\n• Created a web application for technicians to view model predictions and schedule maintenance\\n• Integrated model into industrial engineering team’s equipment maintenance process\\n• Leveraged SQL and other database languages to conduct complex queries \\n• Applied analytics and statistical modeling to collect, analyze, and interpret data sets \\n• Developed new modeling approaches to explore data sources and technology opportunities\\n• Managed a technical team to solve clients’ solutions and expectations\\n• Conducted exploratory data analysis on customer purchasing patterns using R, resulting in improved customer segmentation\\n• Applied unsupervised learning techniques such as k-means clustering and hierarchical clustering to segment customers based on their behavior\\n• Developed a dashboard using Shiny to visualize the segments and provide insights to the business team\\n• Built a convolutional neural network to identify objects in images captured by a camera on an autonomous vehicle\\n• Optimized the model using techniques such as data augmentation and transfer learning\\n• Integrated the model into the vehicle's software system to enable real-time object recognition and decision-making\\n• Developed a machine learning model to identify fraudulent transactions in real time\\n• Incorporated data from multiple sources, including transaction logs, customer behavior patterns, and external databases\\n• Built an API to allow the model to be easily integrated into the company's existing transaction processing system\\n• Trained a Named Entity Recognition Model\\n• Utilized a combination of rule-based and machine learning approaches to create a Named Entity Recognition Model\\n• Integrated the model into the company's electronic health record system to improve data quality and patient outcomes\\n• Built a forecasting model to predict energy demand using historical time series data\\n• Applied seasonal decomposition, autocorrelation analysis, and ARIMA modeling to identify patterns in the data\\n• Developed a dashboard using Shiny to visualize the forecasts and insights for the energy trading team\\n• Developed a recommendation system to suggest products to customers based on their browsing and purchasing history\\n• Used collaborative filtering and content-based filtering techniques to generate personalized recommendations\\n• Built a web application to display the recommendations and allow customers to provide feedback on their preferences\\n\\nProgramming Skills:\\nPython, scikit-learn, web development, data visualization, machine learning, statistics, SQL, database languages, R, Natural Language Processing, Machine Learning, Healthcare, Software Integration, Time Series Analysis, Forecasting, Data Visualization, Software Engineering.\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background_section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
